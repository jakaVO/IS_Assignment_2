{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install torch torchvision torchaudio\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertModel\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yd/typqllh91wbfnhg4gx4s62b00000gn/T/ipykernel_98662/1599986149.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_json(json_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text          label\n",
      "0  \"Until you have a dog you don't understand wha...         COMEDY\n",
      "1  \"Accidentally put grown-up toothpaste on my to...      PARENTING\n",
      "2  Maury Wills, who helped the Los Angeles Dodger...         SPORTS\n",
      "3  For the past 18 months, Hollywood has effectiv...  ENTERTAINMENT\n",
      "4  President issues vow as tensions with China rise.       POLITICS\n"
     ]
    }
   ],
   "source": [
    "json_file_path = 'News_Category_Dataset_IS_course.json'\n",
    "\n",
    "with open(json_file_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "json_data = '[' + ','.join(lines) + ']'\n",
    "df = pd.read_json(json_data)\n",
    "df = df[[\"short_description\", \"category\"]]\n",
    "df = df.rename(columns={\"short_description\": \"text\", \"category\": \"label\"})\n",
    "df = df.loc[:999, :]\n",
    "\n",
    "unique_categories = df[\"label\"].unique()\n",
    "# unique_categories = ['COMEDY' 'PARENTING' 'SPORTS' 'ENTERTAINMENT' 'POLITICS' 'WELLNESS'\n",
    "#  'BUSINESS' 'STYLE & BEAUTY' 'FOOD & DRINK' 'QUEER VOICES' 'HOME & LIVING'\n",
    "#  'BLACK VOICES' 'TRAVEL' 'PARENTS' 'HEALTHY LIVING']\n",
    "\n",
    "category_mapping = {}\n",
    "for index, category in enumerate(unique_categories):\n",
    "    category_mapping[category] = index\n",
    "    \n",
    "#print(category_mapping)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,   146,  1209,  2824,  2508, 26173,  3568,   102,     0,     0]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "example_text = 'I will watch Memento tonight'\n",
    "bert_input = tokenizer(example_text,padding='max_length', max_length = 10, \n",
    "                       truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "print(bert_input['input_ids'])\n",
    "print(bert_input['token_type_ids'])\n",
    "print(bert_input['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "labels = category_mapping\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.labels = [labels[label] for label in df['label']]\n",
    "        self.texts = [tokenizer(\n",
    "            text = \"asd\",\n",
    "            padding='max_length',\n",
    "            max_length=512,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        ) for text in df['text']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 100 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/markmihelic/.pyenv/versions/3.10.13/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(112)\n",
    "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42), \n",
    "                                     [int(.8*len(df)), int(.9*len(df))])\n",
    "\n",
    "print(len(df_train),len(df_val), len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5):\n",
    "\n",
    "        super(BertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, len(unique_categories))\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 11/400 [00:12<07:10,  1.11s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/markmihelic/Documents/FAKS/3. letnik/IS/IS_Assignment_2/bert.ipynb Cell 7\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/markmihelic/Documents/FAKS/3.%20letnik/IS/IS_Assignment_2/bert.ipynb#W6sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m model \u001b[39m=\u001b[39m BertClassifier()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/markmihelic/Documents/FAKS/3.%20letnik/IS/IS_Assignment_2/bert.ipynb#W6sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m LR \u001b[39m=\u001b[39m \u001b[39m1e-6\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/markmihelic/Documents/FAKS/3.%20letnik/IS/IS_Assignment_2/bert.ipynb#W6sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m train(model, df_train, df_val, LR, EPOCHS)\n",
      "\u001b[1;32m/Users/markmihelic/Documents/FAKS/3. letnik/IS/IS_Assignment_2/bert.ipynb Cell 7\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/markmihelic/Documents/FAKS/3.%20letnik/IS/IS_Assignment_2/bert.ipynb#W6sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     total_acc_train \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m acc\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/markmihelic/Documents/FAKS/3.%20letnik/IS/IS_Assignment_2/bert.ipynb#W6sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     model\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/markmihelic/Documents/FAKS/3.%20letnik/IS/IS_Assignment_2/bert.ipynb#W6sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     batch_loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/markmihelic/Documents/FAKS/3.%20letnik/IS/IS_Assignment_2/bert.ipynb#W6sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/markmihelic/Documents/FAKS/3.%20letnik/IS/IS_Assignment_2/bert.ipynb#W6sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m total_acc_val \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    259\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train(model, train_data, val_data, learning_rate, epochs):\n",
    "\n",
    "    train, val = Dataset(train_data), Dataset(val_data)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "            model = model.cuda()\n",
    "            criterion = criterion.cuda()\n",
    "\n",
    "    for epoch_num in range(epochs):\n",
    "\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "\n",
    "            for train_input, train_label in tqdm(train_dataloader):\n",
    "\n",
    "                train_label = train_label.to(device)\n",
    "                mask = train_input['attention_mask'].to(device)\n",
    "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                output = model(input_id, mask)\n",
    "                \n",
    "                batch_loss = criterion(output, train_label.long())\n",
    "                total_loss_train += batch_loss.item()\n",
    "                \n",
    "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "                total_acc_train += acc\n",
    "\n",
    "                model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for val_input, val_label in val_dataloader:\n",
    "\n",
    "                    val_label = val_label.to(device)\n",
    "                    mask = val_input['attention_mask'].to(device)\n",
    "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                    output = model(input_id, mask)\n",
    "\n",
    "                    batch_loss = criterion(output, val_label.long())\n",
    "                    total_loss_val += batch_loss.item()\n",
    "                    \n",
    "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                    total_acc_val += acc\n",
    "            \n",
    "            print(\n",
    "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n",
    "                | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
    "                | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
    "                | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n",
    "                  \n",
    "EPOCHS = 5\n",
    "model = BertClassifier()\n",
    "LR = 1e-6\n",
    "              \n",
    "train(model, df_train, df_val, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.470\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([[0.0828, 0.0000, 1.5016, 2.7696, 3.1907, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 1.1058, 2.9067, 3.2508, 0.0000, 0.2882, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]),\n",
       " tensor([[0.0000, 0.0000, 1.7417, 3.0053, 3.8917, 0.0000, 0.4116, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0754, 0.0000, 1.7596, 2.9623, 3.5517, 0.0000, 1.0431, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]),\n",
       " tensor([[0.0000, 0.0000, 1.5059, 2.8508, 3.1585, 0.0000, 0.6953, 0.0400, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.2372],\n",
       "         [0.0000, 0.0000, 1.8772, 2.9558, 3.9754, 0.0000, 0.2055, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]),\n",
       " tensor([[0.5535, 0.0000, 1.2274, 2.5284, 3.4695, 0.0000, 0.5903, 0.0696, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 1.7958, 3.2971, 3.0503, 0.0000, 0.5243, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.3294]]),\n",
       " tensor([[0.5983, 0.0000, 1.2815, 2.5473, 3.2595, 0.0000, 0.2125, 0.0485, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.3765],\n",
       "         [0.6858, 0.0000, 1.9399, 2.9995, 3.6241, 0.0000, 0.1531, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]),\n",
       " tensor([[0.0000, 0.0000, 1.6187, 3.0319, 3.7485, 0.0000, 0.6084, 0.0246, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2086, 0.0000, 1.6581, 3.7001, 3.6883, 0.0000, 0.0170, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]),\n",
       " tensor([[0.0000, 0.0000, 1.1086, 2.5573, 3.1229, 0.0000, 0.2856, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 1.6463, 2.7408, 3.3736, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]),\n",
       " tensor([[0.1108, 0.0000, 1.4290, 2.6326, 3.6211, 0.0000, 0.5411, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 1.7994, 2.9097, 3.7204, 0.0000, 0.1156, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.1251]]),\n",
       " tensor([[0.0000, 0.0000, 1.4134, 2.7087, 3.4172, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 2.0398, 2.4828, 3.5206, 0.0000, 0.0549, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.6697]]),\n",
       " tensor([[0.0000, 0.0000, 1.1631, 2.6635, 3.0992, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2102, 0.0000, 1.3903, 2.3998, 3.4298, 0.0000, 0.6398, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]),\n",
       " tensor([[0.0877, 0.0000, 1.8261, 3.1498, 3.7579, 0.0000, 0.6597, 0.5178, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.3577],\n",
       "         [0.0000, 0.0000, 1.4444, 2.4545, 3.1769, 0.0000, 0.7692, 0.2383, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]),\n",
       " tensor([[0.0000, 0.0000, 1.7508, 2.7200, 3.6636, 0.0000, 0.3346, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 1.3437, 2.2392, 2.7258, 0.0000, 0.4869, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]),\n",
       " tensor([[0.0000, 0.0000, 1.4485, 3.1952, 3.6289, 0.0000, 0.1616, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0890],\n",
       "         [0.0000, 0.0000, 1.6596, 2.6857, 3.0839, 0.0000, 0.3369, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]),\n",
       " tensor([[0.3829, 0.0000, 1.2651, 3.0483, 3.6197, 0.0000, 0.4291, 0.1726, 0.3743,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2709, 0.0000, 1.6573, 3.1647, 3.4876, 0.0000, 0.1794, 0.0000, 0.0956,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]),\n",
       " tensor([[0.0000e+00, 0.0000e+00, 1.7760e+00, 3.1007e+00, 3.1988e+00, 0.0000e+00,\n",
       "          3.7559e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [1.3604e-03, 0.0000e+00, 1.4999e+00, 2.6114e+00, 2.7727e+00, 0.0000e+00,\n",
       "          6.1367e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00]]),\n",
       " tensor([[0.0630, 0.0000, 1.5767, 2.7699, 3.4394, 0.0000, 0.6825, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 1.6275, 2.6692, 2.9328, 0.0000, 0.0387, 0.3000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.3569]]),\n",
       " tensor([[0.1346, 0.0000, 0.6595, 2.8098, 3.3352, 0.0000, 0.6362, 0.0000, 0.0000,\n",
       "          0.0310, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.9380, 2.4068, 3.4621, 0.0000, 0.6128, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]),\n",
       " tensor([[0.0914, 0.0000, 1.6490, 3.2416, 3.7332, 0.0000, 0.2670, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 1.9780, 2.9172, 4.1850, 0.0000, 0.1796, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.5892]]),\n",
       " tensor([[0.1908, 0.0000, 1.8009, 2.6468, 3.4482, 0.0000, 0.2864, 0.2746, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.2410],\n",
       "         [0.0000, 0.0000, 1.4630, 2.7845, 3.2694, 0.0000, 0.4230, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]),\n",
       " tensor([[0.0000, 0.0000, 1.4591, 3.2904, 3.2730, 0.0000, 0.3581, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 1.7021, 2.9451, 3.6105, 0.0000, 0.0068, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.1103, 0.0000]]),\n",
       " tensor([[0.0000e+00, 0.0000e+00, 1.0621e+00, 2.7099e+00, 3.4589e+00, 0.0000e+00,\n",
       "          9.0177e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [4.0942e-01, 0.0000e+00, 2.0012e+00, 2.7223e+00, 3.2658e+00, 0.0000e+00,\n",
       "          7.1116e-01, 3.1073e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          2.5968e-02]]),\n",
       " tensor([[0.4763, 0.0000, 1.6182, 2.9364, 3.3848, 0.0000, 0.1413, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.1013, 0.0000],\n",
       "         [0.5636, 0.0000, 1.5816, 3.0752, 3.4317, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0609]]),\n",
       " tensor([[0.0000, 0.0000, 1.7515, 3.1151, 3.8325, 0.0000, 0.4043, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.2317],\n",
       "         [0.3603, 0.0000, 1.6897, 3.0068, 3.4105, 0.0000, 0.5955, 0.0058, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.2495]]),\n",
       " tensor([[0.0000, 0.0000, 2.0042, 2.9353, 3.1228, 0.0000, 0.3700, 0.0000, 0.0000,\n",
       "          0.0199, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0762, 0.0000, 1.8635, 2.9333, 3.5517, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.2680, 0.0000, 0.0000, 0.0000]]),\n",
       " tensor([[0.0000, 0.0000, 1.9188, 3.0026, 3.2885, 0.0000, 0.3812, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0201, 0.0000, 2.2167, 3.5858, 3.8835, 0.0000, 0.4792, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]),\n",
       " tensor([[0.0000, 0.0000, 1.0804, 3.0685, 3.3277, 0.0000, 0.5296, 0.0794, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0107, 0.0000, 1.5410, 2.8209, 3.0959, 0.0000, 0.0542, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.1491]]),\n",
       " tensor([[0.0000, 0.0000, 1.9186, 2.9064, 3.5334, 0.0000, 0.7047, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.1368, 0.0000],\n",
       "         [0.3478, 0.0000, 1.8707, 3.2013, 3.1188, 0.0000, 0.1555, 0.0323, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]),\n",
       " tensor([[0.0000, 0.0000, 1.7552, 2.6772, 3.3528, 0.0000, 0.2080, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.2047],\n",
       "         [0.0569, 0.0000, 1.4705, 2.9201, 3.3036, 0.0000, 0.4188, 0.0150, 0.1654,\n",
       "          0.0000, 0.0000, 0.0000, 0.0807]]),\n",
       " tensor([[0.0000, 0.0000, 1.4384, 2.7755, 3.3528, 0.0000, 0.0000, 0.0000, 0.3032,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 1.5779, 2.7121, 2.9582, 0.0000, 0.5142, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]),\n",
       " tensor([[0.1638, 0.0000, 1.6953, 2.5424, 3.2153, 0.0000, 0.0000, 0.1783, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 1.1644, 2.9148, 3.0698, 0.0000, 0.5622, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]),\n",
       " tensor([[0.0000, 0.0000, 1.8379, 2.6037, 3.4808, 0.0000, 0.5873, 0.1657, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0388, 0.0000, 1.2803, 3.2945, 3.3650, 0.0000, 0.3520, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.2637, 0.0000]]),\n",
       " tensor([[0.0000, 0.0000, 1.0952, 2.9573, 3.4599, 0.0000, 0.4632, 0.0408, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1152, 0.0000, 1.4828, 2.4722, 3.2092, 0.0000, 0.4060, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.3852, 0.0000]]),\n",
       " tensor([[0.0000, 0.0000, 1.5784, 3.0891, 3.1505, 0.0000, 0.5221, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 1.3803, 2.9674, 3.4907, 0.0000, 0.4781, 0.2003, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]),\n",
       " tensor([[0.0000, 0.0000, 1.3545, 2.9272, 3.2670, 0.0000, 0.3723, 0.4651, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2099, 0.0000, 1.1550, 2.8480, 3.1399, 0.0000, 0.3707, 0.0000, 0.0816,\n",
       "          0.0000, 0.0000, 0.0000, 0.1667]]),\n",
       " tensor([[0.6366, 0.0000, 1.7817, 2.7352, 3.3620, 0.0000, 0.2166, 0.0860, 0.3199,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 1.9518, 3.2722, 3.4336, 0.0000, 0.4554, 0.1982, 0.0000,\n",
       "          0.0000, 0.0000, 0.0592, 0.0000]]),\n",
       " tensor([[0.0000, 0.0000, 1.7312, 3.0510, 3.0828, 0.0000, 0.3143, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2236, 0.0000, 2.0399, 2.9233, 3.1401, 0.0000, 0.0000, 0.1698, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.3530]]),\n",
       " tensor([[0.3627, 0.0000, 1.4958, 3.1002, 3.2137, 0.0000, 0.3239, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 1.9311, 2.8743, 3.4494, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]),\n",
       " tensor([[0.0912, 0.0000, 1.6770, 2.9341, 3.4849, 0.0000, 0.1590, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2462, 0.0000, 1.3677, 2.3040, 3.2287, 0.0000, 0.1742, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0452]]),\n",
       " tensor([[0.0000, 0.0000, 1.6835, 2.7047, 3.4042, 0.0000, 0.4059, 0.2102, 0.0217,\n",
       "          0.0000, 0.0000, 0.1299, 0.1729],\n",
       "         [0.6036, 0.0000, 0.8830, 2.7664, 2.9419, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]),\n",
       " tensor([[0.0000, 0.0000, 1.5043, 2.6299, 3.3002, 0.0000, 0.5468, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0098, 0.0000, 1.4773, 2.8987, 3.1893, 0.0000, 0.6919, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.1382]]),\n",
       " tensor([[0.2271, 0.0000, 1.4432, 3.2718, 3.7925, 0.0000, 0.4672, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.1091, 0.1515],\n",
       "         [0.0000, 0.0000, 1.7473, 2.8399, 3.5713, 0.0000, 0.2196, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]),\n",
       " tensor([[0.0307, 0.0000, 1.9559, 2.7946, 3.2366, 0.0000, 0.5203, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1774, 0.0000, 1.8590, 2.7034, 3.2672, 0.0000, 0.3904, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]),\n",
       " tensor([[0.0000, 0.0000, 1.7329, 2.9432, 3.1879, 0.0000, 0.2641, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0676, 0.0000],\n",
       "         [0.0000, 0.0000, 1.6637, 2.8064, 3.2182, 0.0000, 0.4142, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]),\n",
       " tensor([[0.0000, 0.0000, 1.6396, 2.5851, 3.3568, 0.0000, 0.2578, 0.0000, 0.0000,\n",
       "          0.2375, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 1.6123, 2.3567, 3.2644, 0.0000, 0.1341, 0.0321, 0.2007,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]),\n",
       " tensor([[0.2207, 0.0000, 0.7467, 2.6539, 3.2381, 0.0000, 0.4129, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.1340],\n",
       "         [0.0861, 0.0000, 1.7221, 3.3856, 3.2713, 0.0000, 0.2611, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]),\n",
       " tensor([[0.0000, 0.0000, 1.4237, 3.4836, 3.3853, 0.0000, 0.2461, 0.0000, 0.2488,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 1.6782, 2.6919, 3.4765, 0.0000, 0.1819, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]),\n",
       " tensor([[0.0000, 0.0000, 1.9117, 3.7621, 3.0485, 0.0000, 0.3716, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.1192, 0.0000],\n",
       "         [0.0000, 0.0000, 1.6391, 3.1963, 3.2366, 0.0000, 0.3314, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]),\n",
       " tensor([[0.0000, 0.0000, 2.0023, 3.0227, 3.5931, 0.0000, 0.2840, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 1.9385, 2.7045, 3.7127, 0.0000, 0.7211, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]),\n",
       " tensor([[0.0000, 0.0000, 1.0079, 3.1223, 3.4978, 0.0000, 0.1337, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1368, 0.0000, 1.5018, 2.9651, 3.8155, 0.0000, 0.1419, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.3931]]),\n",
       " tensor([[0.0000, 0.0000, 1.5662, 2.9559, 3.3084, 0.0000, 0.0765, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.1943],\n",
       "         [0.0000, 0.0000, 1.3378, 3.2641, 3.9563, 0.0000, 0.3534, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]])]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def evaluate(model, test_data):\n",
    "\n",
    "    test = Dataset(test_data)\n",
    "    \n",
    "    outputs = []\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "        model = model.cuda()\n",
    "\n",
    "    total_acc_test = 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for test_input, test_label in test_dataloader:\n",
    "\n",
    "              test_label = test_label.to(device)\n",
    "              mask = test_input['attention_mask'].to(device)\n",
    "              input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "              output = model(input_id, mask)\n",
    "              outputs.append(output)\n",
    "\n",
    "              acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "              total_acc_test += acc\n",
    "    \n",
    "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')\n",
    "    \n",
    "    return outputs\n",
    "    \n",
    "evaluate(model, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.000\n",
      "[tensor([[0.0427, 0.0000, 2.3858, 2.5399, 3.6643, 0.0000, 0.4824, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.2163]])]\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'text': [\"Don't you just love it when you hear the words: fun, laughter and park\"],\n",
    "    'label': [\"ENTERTAINMENT\"]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "result = evaluate(model, df)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
