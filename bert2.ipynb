{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install torch torchvision torchaudio\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertModel\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import pipeline\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yd/typqllh91wbfnhg4gx4s62b00000gn/T/ipykernel_22143/1534193860.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_json(json_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BLACK VOICES': 0, 'BUSINESS': 1, 'COMEDY': 2, 'ENTERTAINMENT': 3, 'FOOD & DRINK': 4, 'HOME & LIVING': 5, 'PARENTING': 6, 'POLITICS': 7, 'QUEER VOICES': 8, 'SPORTS': 9, 'STYLE & BEAUTY': 10, 'TRAVEL': 11, 'WELLNESS': 12}\n",
      "{0: 'BLACK VOICES', 1: 'BUSINESS', 2: 'COMEDY', 3: 'ENTERTAINMENT', 4: 'FOOD & DRINK', 5: 'HOME & LIVING', 6: 'PARENTING', 7: 'POLITICS', 8: 'QUEER VOICES', 9: 'SPORTS', 10: 'STYLE & BEAUTY', 11: 'TRAVEL', 12: 'WELLNESS'}\n"
     ]
    }
   ],
   "source": [
    "json_file_path = 'News_Category_Dataset_IS_course.json'\n",
    "\n",
    "with open(json_file_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "json_data = '[' + ','.join(lines) + ']'\n",
    "df = pd.read_json(json_data)\n",
    "df = df[[\"short_description\", \"category\"]]\n",
    "df = df.rename(columns={\"short_description\": \"text\", \"category\": \"label\"})\n",
    "df = df.loc[:999, :]\n",
    "\n",
    "unique_categories = sorted(df[\"label\"].unique())\n",
    "\n",
    "label2id = {}\n",
    "id2label = {}\n",
    "for index, category in enumerate(unique_categories):\n",
    "    label2id[category] = index\n",
    "for key in label2id.keys():\n",
    "    id2label[label2id[key]] = key\n",
    "    \n",
    "print(label2id)\n",
    "print(id2label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/markmihelic/.pyenv/versions/3.10.13/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "794 99 100\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(unique_categories), id2label=id2label, label2id=label2id)\n",
    "model.to(\"mps\")\n",
    "\n",
    "mask = df[\"text\"].notnull()\n",
    "filtered_df = df[mask]\n",
    "\n",
    "np.random.seed(112)\n",
    "df_train, df_val, df_test = np.split(filtered_df.sample(frac=1, random_state=42), \n",
    "                                     [int(.8*len(filtered_df)), int(.9*len(filtered_df))])\n",
    "\n",
    "print(len(df_train), len(df_val), len(df_test))\n",
    "\n",
    "text_train = df_train[\"text\"].tolist()\n",
    "label_train = df_train[\"label\"]\n",
    "inputs_train = tokenizer(text_train, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "labels_train = torch.tensor(label_train.map(label2id).tolist())\n",
    "\n",
    "inputs_train_to_tensor = []\n",
    "for i in range(len(inputs_train.input_ids)):\n",
    "    obj = {\n",
    "        \"input_ids\": inputs_train.input_ids[i],\n",
    "        \"attention_mask\": inputs_train.attention_mask[i],\n",
    "        \"token_type_ids\": inputs_train.token_type_ids[i],\n",
    "        \"label\": labels_train[i],\n",
    "    }\n",
    "    inputs_train_to_tensor.append(obj)\n",
    "inputs_train = inputs_train_to_tensor\n",
    "\n",
    "text_val = df_val[\"text\"].tolist()\n",
    "label_val = df_val[\"label\"]\n",
    "inputs_val = tokenizer(text_val, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "labels_val = torch.tensor(label_val.map(label2id).tolist())\n",
    "\n",
    "inputs_val_to_tensor = []\n",
    "for i in range(len(inputs_val.input_ids)):\n",
    "    obj = {\n",
    "        \"input_ids\": inputs_val.input_ids[i],\n",
    "        \"attention_mask\": inputs_val.attention_mask[i],\n",
    "        \"token_type_ids\": inputs_val.token_type_ids[i],\n",
    "        \"label\": labels_val[i],\n",
    "    }\n",
    "    inputs_val_to_tensor.append(obj)\n",
    "inputs_val = inputs_val_to_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, inputs, labels):\n",
    "        self.inputs = inputs\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.inputs[idx][\"input_ids\"],\n",
    "            \"attention_mask\": self.inputs[idx][\"attention_mask\"],\n",
    "            \"label\": self.labels[idx],\n",
    "        }\n",
    "        \n",
    "# train_dataset = MyDataset(train_inputs, train_labels)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_train = TensorDataset(inputs_train['input_ids'], inputs_train['attention_mask'], labels_train)\n",
    "dataset_train = Dataset(inputs_train, labels_train)\n",
    "# dataset_val = TensorDataset(inputs_val['input_ids'], inputs_val['attention_mask'], labels_val)\n",
    "dataset_val = Dataset(inputs_val, labels_val)\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    \n",
    "    return {\n",
    "        'Accuracy': acc,\n",
    "        'F1': f1,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/markmihelic/.pyenv/versions/3.10.13/lib/python3.10/site-packages/transformers/training_args.py:1897: UserWarning: `use_mps_device` is deprecated and will be removed in version 5.0 of ðŸ¤— Transformers. `mps` device will be used by default if available similar to the way `cuda` device is used.Therefore, no action from user is required. \n",
      "  warnings.warn(\n",
      "26it [39:59, 92.30s/it]\n",
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 50/150 [00:22<00:25,  3.99it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A/Users/markmihelic/.pyenv/versions/3.10.13/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A                                       \n",
      "                                                \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                                    \n",
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 50/150 [00:22<00:25,  3.99it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8030497431755066, 'eval_Accuracy': 0.8787878787878788, 'eval_F1': 0.528043694559121, 'eval_Precision': 0.515108759553204, 'eval_Recall': 0.5446913580246914, 'eval_runtime': 0.3236, 'eval_samples_per_second': 305.956, 'eval_steps_per_second': 21.633, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 100/150 [00:35<00:11,  4.31it/s]Checkpoint destination directory ./output_dir/checkpoint-100 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A/Users/markmihelic/.pyenv/versions/3.10.13/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A                                       \n",
      "                                                 \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                                    \n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 100/150 [00:36<00:11,  4.31it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9137121438980103, 'eval_Accuracy': 0.8686868686868687, 'eval_F1': 0.5344992460186105, 'eval_Precision': 0.5297325102880659, 'eval_Recall': 0.5409876543209876, 'eval_runtime': 0.2882, 'eval_samples_per_second': 343.505, 'eval_steps_per_second': 24.288, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 150/150 [00:49<00:00,  4.28it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A/Users/markmihelic/.pyenv/versions/3.10.13/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A                                       \n",
      "                                                 \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                                    \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 150/150 [00:49<00:00,  4.28it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                                       \n",
      "                                                 \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 150/150 [00:49<00:00,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8424506187438965, 'eval_Accuracy': 0.8585858585858586, 'eval_F1': 0.5875622173016143, 'eval_Precision': 0.6170510132774284, 'eval_Recall': 0.614320987654321, 'eval_runtime': 0.2595, 'eval_samples_per_second': 381.446, 'eval_steps_per_second': 26.971, 'epoch': 3.0}\n",
      "{'train_runtime': 49.6787, 'train_samples_per_second': 47.948, 'train_steps_per_second': 3.019, 'train_loss': 0.04509725570678711, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=150, training_loss=0.04509725570678711, metrics={'train_runtime': 49.6787, 'train_samples_per_second': 47.948, 'train_steps_per_second': 3.019, 'train_loss': 0.04509725570678711, 'epoch': 3.0})"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./output_dir',\n",
    "    do_train=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    do_eval=True,\n",
    "    use_mps_device=True,\n",
    "    save_steps=100,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_loader.dataset,\n",
    "    eval_dataset=val_loader.dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('fine_tuned_model_dir')\n",
    "tokenizer.save_pretrained('fine_tuned_model_dir')\n",
    "\n",
    "fine_tuned_model = BertForSequenceClassification.from_pretrained('fine_tuned_model_dir')\n",
    "fine_tuned_tokenizer = BertTokenizer.from_pretrained('fine_tuned_model_dir')\n",
    "# nlp = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "nlp = pipeline(\"sentiment-analysis\", model=fine_tuned_model, tokenizer=fine_tuned_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'ENTERTAINMENT', 'score': 0.9979384541511536}]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"Mariah Carey Brings Big, Big Energy To Latto's 2022 BET Awards Performance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:00<00:00, 29.53it/s]/Users/markmihelic/.pyenv/versions/3.10.13/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 29.66it/s]\n"
     ]
    }
   ],
   "source": [
    "text_test = df_test[\"text\"].tolist()\n",
    "label_test = df_test[\"label\"]\n",
    "inputs_test = tokenizer(text_test, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "labels_test = torch.tensor(label_test.map(label2id).tolist())\n",
    "\n",
    "inputs_test_to_tensor = []\n",
    "for i in range(len(inputs_test.input_ids)):\n",
    "    obj = {\n",
    "        \"input_ids\": inputs_test.input_ids[i],\n",
    "        \"attention_mask\": inputs_test.attention_mask[i],\n",
    "        \"token_type_ids\": inputs_test.token_type_ids[i],\n",
    "        \"label\": labels_test[i],\n",
    "    }\n",
    "    inputs_test_to_tensor.append(obj)\n",
    "inputs_test = inputs_test_to_tensor\n",
    "\n",
    "# test_dataset = TensorDataset(inputs_test['input_ids'], inputs_test['attention_mask'], labels_test)\n",
    "test_dataset = Dataset(inputs_test, labels_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# results = [trainer.evaluate(eval_dataset=x) for x in test_loader.dataset]\n",
    "results = trainer.evaluate(eval_dataset=val_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.86%\n",
      "Loss: 84.25%\n",
      "F1: 58.76%\n",
      "Precision: 61.71%\n",
      "Recall: 61.43%\n",
      "Runtime: 59.46%\n",
      "Samples per second: 16648.80%\n",
      "Steps per second: 1177.20%\n",
      "Epochs: 3.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {results['eval_Accuracy']:.2%}\")\n",
    "print(f\"Loss: {results['eval_loss']:.2%}\")\n",
    "print(f\"F1: {results['eval_F1']:.2%}\")\n",
    "print(f\"Precision: {results['eval_Precision']:.2%}\")\n",
    "print(f\"Recall: {results['eval_Recall']:.2%}\")\n",
    "print(f\"Runtime: {results['eval_runtime']:.2%}\")\n",
    "print(f\"Samples per second: {results['eval_samples_per_second']:.2%}\")\n",
    "print(f\"Steps per second: {results['eval_steps_per_second']:.2%}\")\n",
    "print(f\"Epochs: {results['epoch']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
